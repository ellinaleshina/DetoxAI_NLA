{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducing and analyzing the results of the article \"[MODEL EDITING AS A ROBUST AND DENOISED VARI- ANT OF DPO: A CASE STUDY ON TOXICITY](https://arxiv.org/pdf/2405.13967)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном ноутбуке мы хотим воспроизвести полученные в статье результаты, проанализировать применные авторами подходы. Оценить преимущества и недостатки:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В статье основной эксперимент првоодили на GPT-2-Medium, мы тоже будем на ней из-за ее небольшого размера 355M параметров. Выбор параметров модели:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __pref_data_dps__ - pairwise toxic data сгенерированные в [статье](https://arxiv.org/abs/2401.01967)<br>\n",
    "\"The non-toxic sequences are extracted from Wikitext-2, and their toxic counterparts are generated using PPLM\" - Данные взяты из статьи, в репозитории которой не содержится кода по получению пар данных с применением PPLM, лишь одноабзацное описание с упоминанием гиперпараметров обучения GPT-2.\n",
    "<br> Это первая задача проекта - нужно разобраться с генерацией PPLM так как это позволит сгенерировать свои данные разных доменов (не только токсичности, но и например нарушения против религий, расы и тд).<br><br>\n",
    "* __centering__ - параметр центрирования, который удаляет фоновый (частотный) шум, улучшая внимание модели на более редкие и значимые компоненты, которые связаны с токсичным содержанием. Детали будут ниже.<br><br>\n",
    "* __edit_keys__ - фильтр к MLP-Key, причем в Readme авторы написали, что рекомендуют не изменять, так как это не снижает токсичность. В самой статье об этом не упоминается, но если задуматься MLP-Key используется для создания \"ключей\" (keys), которые необходимы для механизма внимания.<br>\n",
    "Ключи определяют, какая часть информации (то есть какие значения) будет выбрана и как сильно она будет влиять на итоговое представление. Применение фильтра к MLP-Key может нарушить корректную работу механизма внимания. Однако сами ключи не несут содержательной информации, которая непосредственно появляется в выходном тексте.\n",
    "Ключи используются для определения релевантности информации, и их изменение может нарушить точность сопоставления, что приведёт к потере эффективности и точности работы модели.\n",
    "<br>Поскольку MLP-Key играет вспомогательную роль и не влияет на непосредственное содержание, фильтрация здесь не имеет смысла — она не повлияет на токсичность напрямую.<br><br>\n",
    "* __edit_values__ - фильтр к MLP-Value<br><br>\n",
    "* __lowest_layer_to_edit__ и __top_k_ranks__ - являются ключевыми гиперпараметрами алгоритма, которые подбирались авторами.<br><br>\n",
    "__k__ — это число правых сингулярных векторов, которые используются для построения проекционной матрицы, нацеленное на выделение токсичного подпространства. Эти векторы помогают определить основные токсичные направления в пространстве эмбеддингов. Чем больше k, тем больше направлений учитывается в токсичном подпространстве. Кода с получением этого значения нет. У GPT-2 это значение довольно низкое - 2, в том время как у других рассмаотренных моделей оно взято 10.<br><br>\n",
    "__L__ — это номер слоя, с которого начинается процесс редактирования.<br>\n",
    "Важно выбрать правильный слой для начала редактирования, так как в верхних слоях модели обрабатываются более сложные и высокоуровневые концепции, такие как токсичность. Редактирование с этого уровня позволяет эффективно удалять токсичную информацию, сохраняя основную способность модели обрабатывать текст."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример начала анализа (не окончен):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# При изменениях в коде проекте эти обновления будут автоматически подгружаться в ноутбук\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Настройка путей для импорта модулей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No CUDA_VISIBLE_DEVICES found. Setting to 0.\n",
      "PROJECT_ROOT: 'detox-edit'\n",
      "PYTHONPATH: 'detox-edit':\n",
      "HF_HOME: 'detox-edit'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import inspect\n",
    "import argparse\n",
    "import numpy as np\n",
    "from detox import DeToxEdit\n",
    "import torch\n",
    "\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0, parentdir)\n",
    "\n",
    "from utils.startup import main\n",
    "from evaluate_model import evaluate_model\n",
    "\n",
    "if '__file__' in globals():\n",
    "    parser = argparse.ArgumentParser(description='DeTox')\n",
    "    parser.add_argument('--config_file', default='gpt2-medium.ini', type=str, help='Config Filename. E.g. gpt2-medium.ini')\n",
    "    args = parser.parse_args()\n",
    "    config_filename = args.config_file\n",
    "else:\n",
    "    config_filename = 'gpt2-medium.ini'\n",
    "\n",
    "config = main(config_filename=config_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка модели GPT-2 и токенизатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model gpt2 loaded.\n"
     ]
    }
   ],
   "source": [
    "from utils.model_utils import load_large_model\n",
    "from detox import DeToxEdit\n",
    "\n",
    "model_id = 'gpt2'\n",
    "model, tokenizer = load_large_model(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Слои для изменений, указанные в статье для GPT-2, как уже упомяналось, кода по определению этих границ нет, лишь небольшое текстовое описание в самой статье"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_layer = 10\n",
    "upper_layer = 24\n",
    "\n",
    "layer_range = np.arange(lower_layer, upper_layer) if lower_layer != -1 and upper_layer != -1 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "editor = DeToxEdit(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    pref_data_dps=500,\n",
    "    centering=True,\n",
    "    top_k_ranks=2,\n",
    "    edit_layer_range=layer_range,\n",
    "    random_dps=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Авторы статьи проводят центрирование, но при этом не указывает почему оно имеет значение, при этом допускают его в качестве параметра. Хочется понять как центрирование на самом деле влияет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loaded 500 preferred and 500 non-preferred samples.\n",
      "INFO:root:Batch 1/10 of size 50\n",
      "INFO:root:Batch 2/10 of size 50\n",
      "INFO:root:Batch 3/10 of size 50\n",
      "INFO:root:Batch 4/10 of size 50\n",
      "INFO:root:Batch 5/10 of size 50\n",
      "INFO:root:Batch 6/10 of size 50\n",
      "INFO:root:Batch 7/10 of size 50\n",
      "INFO:root:Batch 8/10 of size 50\n",
      "INFO:root:Batch 9/10 of size 50\n",
      "INFO:root:Batch 10/10 of size 50\n",
      "INFO:root:Hidden sent: torch.Size([24, 500, 1024])\n",
      "INFO:root:Batch 1/10 of size 50\n",
      "INFO:root:Batch 2/10 of size 50\n",
      "INFO:root:Batch 3/10 of size 50\n",
      "INFO:root:Batch 4/10 of size 50\n",
      "INFO:root:Batch 5/10 of size 50\n",
      "INFO:root:Batch 6/10 of size 50\n",
      "INFO:root:Batch 7/10 of size 50\n",
      "INFO:root:Batch 8/10 of size 50\n",
      "INFO:root:Batch 9/10 of size 50\n",
      "INFO:root:Batch 10/10 of size 50\n",
      "INFO:root:Hidden sent: torch.Size([24, 500, 1024])\n",
      "INFO:root:Preference matrix calculated.\n",
      "INFO:root:Centering: Removing first singular vector from preference matrix.\n"
     ]
    }
   ],
   "source": [
    "ats, preference_matrix  = editor.get_ats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loaded 500 preferred and 500 non-preferred samples.\n",
      "INFO:root:Batch 1/10 of size 50\n",
      "INFO:root:Batch 2/10 of size 50\n",
      "INFO:root:Batch 3/10 of size 50\n",
      "INFO:root:Batch 4/10 of size 50\n",
      "INFO:root:Batch 5/10 of size 50\n",
      "INFO:root:Batch 6/10 of size 50\n",
      "INFO:root:Batch 7/10 of size 50\n",
      "INFO:root:Batch 8/10 of size 50\n",
      "INFO:root:Batch 9/10 of size 50\n",
      "INFO:root:Batch 10/10 of size 50\n",
      "INFO:root:Hidden sent: torch.Size([24, 500, 1024])\n",
      "INFO:root:Batch 1/10 of size 50\n",
      "INFO:root:Batch 2/10 of size 50\n",
      "INFO:root:Batch 3/10 of size 50\n",
      "INFO:root:Batch 4/10 of size 50\n",
      "INFO:root:Batch 5/10 of size 50\n",
      "INFO:root:Batch 6/10 of size 50\n",
      "INFO:root:Batch 7/10 of size 50\n",
      "INFO:root:Batch 8/10 of size 50\n",
      "INFO:root:Batch 9/10 of size 50\n",
      "INFO:root:Batch 10/10 of size 50\n",
      "INFO:root:Hidden sent: torch.Size([24, 500, 1024])\n",
      "INFO:root:Preference matrix calculated.\n",
      "INFO:root:No centering: No removing first singular vector from preference matrix.\n"
     ]
    }
   ],
   "source": [
    "not_center_ats, not_center_preference_matrix = editor.get_ats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:SVD of ATS calculated.\n",
      "INFO:root:SVD of ATS calculated.\n"
     ]
    }
   ],
   "source": [
    "svd = editor.svd_on_ats(ats)\n",
    "not_center_svd = editor.svd_on_ats(not_center_ats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 correlation between centered and non-centered: 0.05186564475297928\n",
      "Layer 1 correlation between centered and non-centered: 0.059206850826740265\n",
      "Layer 2 correlation between centered and non-centered: 0.059118837118148804\n",
      "Layer 3 correlation between centered and non-centered: 0.057201966643333435\n",
      "Layer 4 correlation between centered and non-centered: 0.052401527762413025\n",
      "Layer 5 correlation between centered and non-centered: 0.04660128057003021\n",
      "Layer 6 correlation between centered and non-centered: 0.04584299772977829\n",
      "Layer 7 correlation between centered and non-centered: 0.044945117086172104\n",
      "Layer 8 correlation between centered and non-centered: 0.04558739438652992\n",
      "Layer 9 correlation between centered and non-centered: 0.045619018375873566\n",
      "Layer 10 correlation between centered and non-centered: 0.04570295289158821\n",
      "Layer 11 correlation between centered and non-centered: 0.047272924333810806\n",
      "Layer 12 correlation between centered and non-centered: 0.048108987510204315\n",
      "Layer 13 correlation between centered and non-centered: 0.04828518256545067\n",
      "Layer 14 correlation between centered and non-centered: 0.04700256139039993\n",
      "Layer 15 correlation between centered and non-centered: 0.04743390530347824\n",
      "Layer 16 correlation between centered and non-centered: 0.04461781308054924\n",
      "Layer 17 correlation between centered and non-centered: 0.044303592294454575\n",
      "Layer 18 correlation between centered and non-centered: 0.04400542005896568\n",
      "Layer 19 correlation between centered and non-centered: 0.04227079823613167\n",
      "Layer 20 correlation between centered and non-centered: 0.04097043350338936\n",
      "Layer 21 correlation between centered and non-centered: 0.040796034038066864\n",
      "Layer 22 correlation between centered and non-centered: 0.0396575890481472\n",
      "Layer 23 correlation between centered and non-centered: 0.04422437399625778\n"
     ]
    }
   ],
   "source": [
    "for layer_num in range(preference_matrix.shape[0]):\n",
    "    centered_flat = preference_matrix[layer_num].flatten()\n",
    "    noncentered_flat = not_center_preference_matrix[layer_num].flatten()\n",
    "    correlation = torch.corrcoef(torch.stack([centered_flat, noncentered_flat]))[0, 1]\n",
    "    print(f\"Layer {layer_num} correlation between centered and non-centered: {correlation.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_subspace = editor.find_p_toxic(svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edited_model = editor.edit_model(toxic_subspace, edit_keys=True, edit_values=True, layer_range=layer_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl, tox = evaluate_model(edited_model, tokenizer,\n",
    "               return_perplexity=True, return_toxicity=True, display_gen=True)\n",
    "print(f'{model_id} - Perplexity: {ppl}, Toxicity: {tox}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
